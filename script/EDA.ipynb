{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate,Dropout\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawData = pd.read_csv('../input/train.csv')\n",
    "#rawData = pd.read_csv('../input/train_sample.csv')\n",
    "train_df = pd.read_csv('../input/train.csv', nrows=80000,parse_dates=['click_time','attributed_time'])\n",
    "rawData = pd.read_csv('../input/train_sample.csv', parse_dates=['click_time','attributed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data  = rawData.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['fake1'] = ''\n",
    "test_data['fake2'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_day_6,Data_day_7,Data_day_8,Data_day_9 = newFunc.splitDataDay(rawData)\n",
    "pre_Day_6,pre_Day_7,pre_Day_8,pre_Day_9 = newFunc.splitDataDay(train_df)\n",
    "test_Day_6,test_Day_7,test_Day_8,test_Day_9 = newFunc.splitDataDay(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5011, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_day_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5011, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Day_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 0s 129us/step - loss: 7.1017 - acc: 0.5542 - val_loss: 7.4031 - val_acc: 0.5357\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 7.2979 - acc: 0.5409 - val_loss: 7.5231 - val_acc: 0.5272\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 7.3933 - acc: 0.5356 - val_loss: 7.6732 - val_acc: 0.5187\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 7.2977 - acc: 0.5406 - val_loss: 7.7927 - val_acc: 0.5112\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 7.2714 - acc: 0.5432 - val_loss: 7.8879 - val_acc: 0.5052\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 7.2929 - acc: 0.5422 - val_loss: 4.8664 - val_acc: 0.6948\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 6.6297 - acc: 0.5835 - val_loss: 3.2284 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 20us/step - loss: 6.0946 - acc: 0.6158 - val_loss: 2.5525 - val_acc: 0.8399\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 5.8606 - acc: 0.6317 - val_loss: 2.5844 - val_acc: 0.8379\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 5.8554 - acc: 0.6324 - val_loss: 2.7831 - val_acc: 0.8254\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 12us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 0s 152us/step - loss: 7.6799 - acc: 0.5176 - val_loss: 1.4871 - val_acc: 0.9067\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 6.8684 - acc: 0.5689 - val_loss: 0.9305 - val_acc: 0.9416\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 21us/step - loss: 6.6985 - acc: 0.5788 - val_loss: 0.8351 - val_acc: 0.9476\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 24us/step - loss: 6.3804 - acc: 0.5991 - val_loss: 0.7556 - val_acc: 0.9526\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 26us/step - loss: 6.2108 - acc: 0.6104 - val_loss: 0.7237 - val_acc: 0.9546\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 25us/step - loss: 6.5873 - acc: 0.5865 - val_loss: 0.6840 - val_acc: 0.9571\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 6.4970 - acc: 0.5918 - val_loss: 0.6522 - val_acc: 0.9591\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 25us/step - loss: 6.3113 - acc: 0.6028 - val_loss: 0.6442 - val_acc: 0.9596\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 24us/step - loss: 6.1894 - acc: 0.6108 - val_loss: 0.6442 - val_acc: 0.9596\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 5.7174 - acc: 0.6407 - val_loss: 0.6285 - val_acc: 0.9606\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 19us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 169us/step - loss: 11.9383 - acc: 0.2495 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 12.0020 - acc: 0.2462 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 11.8481 - acc: 0.2552 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 24us/step - loss: 12.1185 - acc: 0.2379 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 26us/step - loss: 12.2247 - acc: 0.2315 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 25us/step - loss: 12.1610 - acc: 0.2352 - val_loss: 15.9026 - val_acc: 0.0015\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 25us/step - loss: 12.0780 - acc: 0.2409 - val_loss: 15.8390 - val_acc: 0.0055\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 24us/step - loss: 11.2063 - acc: 0.2951 - val_loss: 13.6525 - val_acc: 0.1431\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 10.7344 - acc: 0.3250 - val_loss: 12.8973 - val_acc: 0.1905\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 24us/step - loss: 10.5011 - acc: 0.3400 - val_loss: 12.8176 - val_acc: 0.1955\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 21us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 193us/step - loss: 3.2671 - acc: 0.7941 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 3.3520 - acc: 0.7888 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.1558 - acc: 0.8014 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.3468 - acc: 0.7894 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.1823 - acc: 0.7997 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.3415 - acc: 0.7901 - val_loss: 1.2253 - val_acc: 0.9227\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 3.2091 - acc: 0.7987 - val_loss: 0.6124 - val_acc: 0.9616\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 2.4293 - acc: 0.8473 - val_loss: 0.2785 - val_acc: 0.9825\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 2.3869 - acc: 0.8503 - val_loss: 0.1672 - val_acc: 0.9895\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 2.0952 - acc: 0.8683 - val_loss: 0.1194 - val_acc: 0.9925\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 23us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 209us/step - loss: 3.3741 - acc: 0.7881 - val_loss: 0.0638 - val_acc: 0.9960\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 16us/step - loss: 3.0392 - acc: 0.8087 - val_loss: 0.0638 - val_acc: 0.9960\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.1932 - acc: 0.7987 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.1507 - acc: 0.8007 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 2.7317 - acc: 0.8287 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 2.6573 - acc: 0.8327 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 2.4406 - acc: 0.8463 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 2.2808 - acc: 0.8566 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 29us/step - loss: 2.3443 - acc: 0.8516 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 2.2119 - acc: 0.8613 - val_loss: 0.0558 - val_acc: 0.9965\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 30us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 221us/step - loss: 7.7062 - acc: 0.5156 - val_loss: 13.9943 - val_acc: 0.1212\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 16us/step - loss: 7.7337 - acc: 0.5133 - val_loss: 13.8273 - val_acc: 0.1317\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 16us/step - loss: 7.4210 - acc: 0.5336 - val_loss: 12.1428 - val_acc: 0.2374\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 6.5394 - acc: 0.5888 - val_loss: 10.4022 - val_acc: 0.3466\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 16us/step - loss: 6.4281 - acc: 0.5961 - val_loss: 8.7396 - val_acc: 0.4509\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 6.3118 - acc: 0.6031 - val_loss: 6.5391 - val_acc: 0.5880\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 6.1683 - acc: 0.6128 - val_loss: 6.0988 - val_acc: 0.6170\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 5.9720 - acc: 0.6248 - val_loss: 5.8443 - val_acc: 0.6329\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 5.5907 - acc: 0.6487 - val_loss: 3.7293 - val_acc: 0.7656\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 4.6992 - acc: 0.7049 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 36us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 247us/step - loss: 1.6869 - acc: 0.8942 - val_loss: 0.0399 - val_acc: 0.9975\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 21us/step - loss: 1.6554 - acc: 0.8955 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 1.2043 - acc: 0.9245 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 23us/step - loss: 0.9179 - acc: 0.9424 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 0.6208 - acc: 0.9607 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 0.7641 - acc: 0.9521 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - ETA: 0s - loss: 0.6546 - acc: 0.959 - 0s 24us/step - loss: 0.6368 - acc: 0.9601 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 20us/step - loss: 0.5996 - acc: 0.9624 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 0.5254 - acc: 0.9671 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 20us/step - loss: 0.6050 - acc: 0.9621 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 39us/step\n",
      "Train on 3006 samples, validate on 2005 samples\n",
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 1s 266us/step - loss: 7.0751 - acc: 0.5552 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 0s 17us/step - loss: 6.8162 - acc: 0.5712 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 0s 20us/step - loss: 5.1075 - acc: 0.6790 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 4.1052 - acc: 0.7418 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.4741 - acc: 0.7818 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 0s 18us/step - loss: 3.1507 - acc: 0.8021 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 2.6149 - acc: 0.8357 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 0s 22us/step - loss: 2.0635 - acc: 0.8703 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 0s 20us/step - loss: 2.0740 - acc: 0.8699 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 0s 19us/step - loss: 1.8883 - acc: 0.8812 - val_loss: 0.0161 - val_acc: 0.9990\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "5011/5011 [==============================] - 0s 39us/step\n",
      "[0]\ttrain-auc:0.85155\ttest-auc:0.748168\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[5]\ttrain-auc:0.999967\ttest-auc:0.691475\n",
      "[10]\ttrain-auc:1\ttest-auc:0.670246\n",
      "[15]\ttrain-auc:1\ttest-auc:0.720696\n",
      "[20]\ttrain-auc:1\ttest-auc:0.751915\n",
      "[25]\ttrain-auc:1\ttest-auc:0.722278\n",
      "[30]\ttrain-auc:1\ttest-auc:0.719447\n",
      "[35]\ttrain-auc:1\ttest-auc:0.707792\n",
      "[40]\ttrain-auc:1\ttest-auc:0.685981\n",
      "[45]\ttrain-auc:1\ttest-auc:0.680653\n",
      "[50]\ttrain-auc:1\ttest-auc:0.662837\n",
      "[55]\ttrain-auc:1\ttest-auc:0.65318\n",
      "[60]\ttrain-auc:1\ttest-auc:0.656677\n",
      "[65]\ttrain-auc:1\ttest-auc:0.657509\n",
      "[70]\ttrain-auc:1\ttest-auc:0.67033\n",
      "[75]\ttrain-auc:1\ttest-auc:0.666001\n",
      "[80]\ttrain-auc:1\ttest-auc:0.654679\n",
      "[85]\ttrain-auc:1\ttest-auc:0.647852\n",
      "[90]\ttrain-auc:1\ttest-auc:0.636197\n",
      "[95]\ttrain-auc:1\ttest-auc:0.667499\n",
      "[100]\ttrain-auc:1\ttest-auc:0.684316\n",
      "[105]\ttrain-auc:1\ttest-auc:0.707126\n",
      "[110]\ttrain-auc:1\ttest-auc:0.68981\n",
      "[115]\ttrain-auc:1\ttest-auc:0.678155\n",
      "Stopping. Best iteration:\n",
      "[19]\ttrain-auc:1\ttest-auc:0.7669\n",
      "\n",
      "5011/5011 [==============================] - 0s 44us/step\n",
      "5011/5011 [==============================] - 0s 41us/step\n",
      "5011/5011 [==============================] - 0s 46us/step\n",
      "5011/5011 [==============================] - 0s 45us/step\n",
      "5011/5011 [==============================] - 0s 47us/step\n",
      "5011/5011 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011/5011 [==============================] - 0s 48us/step\n",
      "5011/5011 [==============================] - 0s 50us/step\n"
     ]
    }
   ],
   "source": [
    "newFunc.trainingPipeline(rawData=Data_day_6,epochs=10,name='Day_6')\n",
    "preData6 =  newFunc.resultGenea(rawData=test_Day_6,name='Day_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 1s 64us/step - loss: 8.5223 - acc: 0.4646 - val_loss: 15.7111 - val_acc: 0.0118\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 0s 11us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 1s 66us/step - loss: 10.5944 - acc: 0.3342 - val_loss: 1.6628 - val_acc: 0.8950\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 0s 12us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 1s 70us/step - loss: 8.5075 - acc: 0.4654 - val_loss: 10.1837 - val_acc: 0.3592\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 0s 15us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 1s 71us/step - loss: 4.6128 - acc: 0.7101 - val_loss: 2.4856 - val_acc: 0.8436\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 0s 13us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 2s 80us/step - loss: 12.9034 - acc: 0.1889 - val_loss: 15.8107 - val_acc: 0.0055\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 1s 16us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 2s 83us/step - loss: 2.4530 - acc: 0.8458 - val_loss: 0.0448 - val_acc: 0.9972\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 0s 15us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 2s 82us/step - loss: 6.2607 - acc: 0.6064 - val_loss: 3.0198 - val_acc: 0.8099\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 1s 16us/step\n",
      "Train on 19435 samples, validate on 12958 samples\n",
      "Epoch 1/1\n",
      "19435/19435 [==============================] - 2s 88us/step - loss: 4.4063 - acc: 0.7228 - val_loss: 0.0448 - val_acc: 0.9972\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "32393/32393 [==============================] - 1s 16us/step\n",
      "[0]\ttrain-auc:0.913435\ttest-auc:0.639214\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[5]\ttrain-auc:0.998682\ttest-auc:0.796842\n",
      "[10]\ttrain-auc:0.999722\ttest-auc:0.804263\n",
      "[15]\ttrain-auc:0.999778\ttest-auc:0.822233\n",
      "[20]\ttrain-auc:0.99985\ttest-auc:0.840435\n",
      "[25]\ttrain-auc:0.999833\ttest-auc:0.837082\n",
      "[30]\ttrain-auc:0.99984\ttest-auc:0.836877\n",
      "[35]\ttrain-auc:0.999865\ttest-auc:0.842512\n",
      "[40]\ttrain-auc:0.999884\ttest-auc:0.846813\n",
      "[45]\ttrain-auc:0.999918\ttest-auc:0.844954\n",
      "[50]\ttrain-auc:0.999925\ttest-auc:0.853084\n",
      "[55]\ttrain-auc:0.999928\ttest-auc:0.854931\n",
      "[60]\ttrain-auc:0.999931\ttest-auc:0.859576\n",
      "[65]\ttrain-auc:0.999934\ttest-auc:0.857714\n",
      "[70]\ttrain-auc:0.999938\ttest-auc:0.858507\n",
      "[75]\ttrain-auc:0.999947\ttest-auc:0.859386\n",
      "[80]\ttrain-auc:0.999954\ttest-auc:0.859549\n",
      "[85]\ttrain-auc:0.999946\ttest-auc:0.858638\n",
      "[90]\ttrain-auc:0.999953\ttest-auc:0.861227\n",
      "[95]\ttrain-auc:0.999946\ttest-auc:0.861926\n",
      "[100]\ttrain-auc:0.999963\ttest-auc:0.86105\n",
      "[105]\ttrain-auc:0.999968\ttest-auc:0.856527\n",
      "[110]\ttrain-auc:0.999967\ttest-auc:0.854085\n",
      "[115]\ttrain-auc:0.999967\ttest-auc:0.854034\n",
      "[120]\ttrain-auc:0.999977\ttest-auc:0.857049\n",
      "[125]\ttrain-auc:0.999975\ttest-auc:0.855004\n",
      "[130]\ttrain-auc:0.999982\ttest-auc:0.85681\n",
      "[135]\ttrain-auc:0.999987\ttest-auc:0.857944\n",
      "[140]\ttrain-auc:0.999986\ttest-auc:0.857982\n",
      "[145]\ttrain-auc:0.999989\ttest-auc:0.858222\n",
      "[150]\ttrain-auc:0.99999\ttest-auc:0.858195\n",
      "[155]\ttrain-auc:0.999994\ttest-auc:0.858406\n",
      "[160]\ttrain-auc:0.999995\ttest-auc:0.863057\n",
      "[165]\ttrain-auc:0.999994\ttest-auc:0.864766\n",
      "[170]\ttrain-auc:0.999994\ttest-auc:0.862883\n",
      "[175]\ttrain-auc:0.999997\ttest-auc:0.861531\n",
      "[180]\ttrain-auc:0.999997\ttest-auc:0.860453\n",
      "[185]\ttrain-auc:0.999998\ttest-auc:0.860431\n",
      "[190]\ttrain-auc:0.999999\ttest-auc:0.86104\n",
      "[195]\ttrain-auc:0.999999\ttest-auc:0.862789\n",
      "[200]\ttrain-auc:0.999999\ttest-auc:0.862373\n",
      "[205]\ttrain-auc:0.999999\ttest-auc:0.861573\n",
      "[210]\ttrain-auc:0.999999\ttest-auc:0.862491\n",
      "[215]\ttrain-auc:0.999999\ttest-auc:0.862755\n",
      "[220]\ttrain-auc:1\ttest-auc:0.862211\n",
      "[225]\ttrain-auc:1\ttest-auc:0.859994\n",
      "[230]\ttrain-auc:1\ttest-auc:0.861534\n",
      "[235]\ttrain-auc:1\ttest-auc:0.86039\n",
      "[240]\ttrain-auc:1\ttest-auc:0.859467\n",
      "[245]\ttrain-auc:1\ttest-auc:0.860997\n",
      "[250]\ttrain-auc:1\ttest-auc:0.860944\n",
      "[255]\ttrain-auc:1\ttest-auc:0.86113\n",
      "[260]\ttrain-auc:1\ttest-auc:0.862525\n",
      "[265]\ttrain-auc:1\ttest-auc:0.864036\n",
      "Stopping. Best iteration:\n",
      "[167]\ttrain-auc:0.999994\ttest-auc:0.864955\n",
      "\n",
      "32393/32393 [==============================] - 1s 18us/step\n",
      "32393/32393 [==============================] - 1s 17us/step\n",
      "32393/32393 [==============================] - 1s 18us/step\n",
      "32393/32393 [==============================] - 1s 18us/step\n",
      "32393/32393 [==============================] - 1s 18us/step\n",
      "32393/32393 [==============================] - 1s 18us/step\n",
      "32393/32393 [==============================] - 1s 19us/step\n",
      "32393/32393 [==============================] - 1s 17us/step\n"
     ]
    }
   ],
   "source": [
    "newFunc.trainingPipeline(rawData=Data_day_7,epochs=1,name='Day_7')\n",
    "preData7 =  newFunc.resultGenea(rawData=test_Day_7,name='Day_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 87us/step - loss: 4.3417 - acc: 0.7271 - val_loss: 0.2546 - val_acc: 0.9841\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 19us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 89us/step - loss: 3.7531 - acc: 0.7641 - val_loss: 0.1222 - val_acc: 0.9924\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 19us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 95us/step - loss: 12.5356 - acc: 0.2120 - val_loss: 15.9026 - val_acc: 0.0000e+00\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 22us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 106us/step - loss: 6.9858 - acc: 0.5609 - val_loss: 14.9262 - val_acc: 0.0617\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 21us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 105us/step - loss: 3.1669 - acc: 0.8010 - val_loss: 0.3834 - val_acc: 0.9759\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 24us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 104us/step - loss: 4.8437 - acc: 0.6954 - val_loss: 6.5992 - val_acc: 0.5857\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 22us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 107us/step - loss: 4.5166 - acc: 0.7159 - val_loss: 1.6024 - val_acc: 0.8992\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 23us/step\n",
      "Train on 20421 samples, validate on 13614 samples\n",
      "Epoch 1/1\n",
      "20421/20421 [==============================] - 2s 108us/step - loss: 6.1946 - acc: 0.6104 - val_loss: 15.4210 - val_acc: 0.0298\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "34035/34035 [==============================] - 1s 23us/step\n",
      "[0]\ttrain-auc:0.960609\ttest-auc:0.746048\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[5]\ttrain-auc:0.998251\ttest-auc:0.881056\n",
      "[10]\ttrain-auc:0.999184\ttest-auc:0.868103\n",
      "[15]\ttrain-auc:0.99963\ttest-auc:0.876328\n",
      "[20]\ttrain-auc:0.999782\ttest-auc:0.886927\n",
      "[25]\ttrain-auc:0.999824\ttest-auc:0.88216\n",
      "[30]\ttrain-auc:0.999822\ttest-auc:0.892071\n",
      "[35]\ttrain-auc:0.999848\ttest-auc:0.887757\n",
      "[40]\ttrain-auc:0.999868\ttest-auc:0.884692\n",
      "[45]\ttrain-auc:0.999875\ttest-auc:0.889138\n",
      "[50]\ttrain-auc:0.999883\ttest-auc:0.887118\n",
      "[55]\ttrain-auc:0.999899\ttest-auc:0.888079\n",
      "[60]\ttrain-auc:0.999897\ttest-auc:0.887989\n",
      "[65]\ttrain-auc:0.999905\ttest-auc:0.889573\n",
      "[70]\ttrain-auc:0.999912\ttest-auc:0.893636\n",
      "[75]\ttrain-auc:0.999927\ttest-auc:0.887006\n",
      "[80]\ttrain-auc:0.999933\ttest-auc:0.891038\n",
      "[85]\ttrain-auc:0.999938\ttest-auc:0.88829\n",
      "[90]\ttrain-auc:0.999932\ttest-auc:0.887751\n",
      "[95]\ttrain-auc:0.999936\ttest-auc:0.88749\n",
      "[100]\ttrain-auc:0.999939\ttest-auc:0.887806\n",
      "[105]\ttrain-auc:0.999941\ttest-auc:0.893537\n",
      "[110]\ttrain-auc:0.999943\ttest-auc:0.894659\n",
      "[115]\ttrain-auc:0.999947\ttest-auc:0.893148\n",
      "[120]\ttrain-auc:0.999951\ttest-auc:0.895484\n",
      "[125]\ttrain-auc:0.999954\ttest-auc:0.892386\n",
      "[130]\ttrain-auc:0.999952\ttest-auc:0.891105\n",
      "[135]\ttrain-auc:0.999952\ttest-auc:0.893041\n",
      "[140]\ttrain-auc:0.999954\ttest-auc:0.891435\n",
      "[145]\ttrain-auc:0.999954\ttest-auc:0.893575\n",
      "[150]\ttrain-auc:0.999956\ttest-auc:0.892708\n",
      "[155]\ttrain-auc:0.999956\ttest-auc:0.892071\n",
      "[160]\ttrain-auc:0.999956\ttest-auc:0.889392\n",
      "[165]\ttrain-auc:0.999956\ttest-auc:0.891242\n",
      "[170]\ttrain-auc:0.999956\ttest-auc:0.889561\n",
      "[175]\ttrain-auc:0.999957\ttest-auc:0.890337\n",
      "[180]\ttrain-auc:0.999957\ttest-auc:0.890802\n",
      "[185]\ttrain-auc:0.999957\ttest-auc:0.891105\n",
      "[190]\ttrain-auc:0.999957\ttest-auc:0.889769\n",
      "[195]\ttrain-auc:0.999957\ttest-auc:0.889476\n",
      "[200]\ttrain-auc:0.999957\ttest-auc:0.890042\n",
      "[205]\ttrain-auc:0.999958\ttest-auc:0.889857\n",
      "[210]\ttrain-auc:0.999958\ttest-auc:0.890852\n",
      "[215]\ttrain-auc:0.99996\ttest-auc:0.890859\n",
      "[220]\ttrain-auc:0.99996\ttest-auc:0.890307\n",
      "Stopping. Best iteration:\n",
      "[120]\ttrain-auc:0.999951\ttest-auc:0.895484\n",
      "\n",
      "34035/34035 [==============================] - 1s 24us/step\n",
      "34035/34035 [==============================] - 1s 30us/step\n",
      "34035/34035 [==============================] - 1s 25us/step\n",
      "34035/34035 [==============================] - 1s 25us/step\n",
      "34035/34035 [==============================] - 1s 25us/step\n",
      "34035/34035 [==============================] - 1s 24us/step\n",
      "34035/34035 [==============================] - 1s 32us/step\n",
      "34035/34035 [==============================] - 1s 29us/step\n"
     ]
    }
   ],
   "source": [
    "newFunc.trainingPipeline(rawData=Data_day_8,epochs=1,name='Day_8')\n",
    "preData8 =  newFunc.resultGenea(rawData=test_Day_8,name='Day_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 2s 135us/step - loss: 3.3635 - acc: 0.7886 - val_loss: 0.0296 - val_acc: 0.9982\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 31us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 2s 139us/step - loss: 6.5891 - acc: 0.5857 - val_loss: 3.0130 - val_acc: 0.8109\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 33us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 158us/step - loss: 11.5075 - acc: 0.2764 - val_loss: 14.0545 - val_acc: 0.1170\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 31us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 154us/step - loss: 11.0174 - acc: 0.3074 - val_loss: 15.8615 - val_acc: 0.0035\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 36us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 152us/step - loss: 3.9599 - acc: 0.7510 - val_loss: 0.8808 - val_acc: 0.9448\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 36us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 160us/step - loss: 9.2209 - acc: 0.4203 - val_loss: 11.9059 - val_acc: 0.2523\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 35us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 166us/step - loss: 8.1082 - acc: 0.4905 - val_loss: 9.5585 - val_acc: 0.3991\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 39us/step\n",
      "Train on 17136 samples, validate on 11425 samples\n",
      "Epoch 1/1\n",
      "17136/17136 [==============================] - 3s 166us/step - loss: 3.1357 - acc: 0.8030 - val_loss: 0.0296 - val_acc: 0.9982\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "28561/28561 [==============================] - 1s 38us/step\n",
      "[0]\ttrain-auc:0.919518\ttest-auc:0.842391\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[5]\ttrain-auc:0.999281\ttest-auc:0.889447\n",
      "[10]\ttrain-auc:0.999903\ttest-auc:0.910257\n",
      "[15]\ttrain-auc:0.999989\ttest-auc:0.905352\n",
      "[20]\ttrain-auc:0.999991\ttest-auc:0.910534\n",
      "[25]\ttrain-auc:0.999991\ttest-auc:0.911997\n",
      "[30]\ttrain-auc:0.99998\ttest-auc:0.908943\n",
      "[35]\ttrain-auc:0.999987\ttest-auc:0.909346\n",
      "[40]\ttrain-auc:0.99998\ttest-auc:0.904822\n",
      "[45]\ttrain-auc:0.999993\ttest-auc:0.908177\n",
      "[50]\ttrain-auc:0.999996\ttest-auc:0.905832\n",
      "[55]\ttrain-auc:0.999991\ttest-auc:0.904912\n",
      "[60]\ttrain-auc:0.999991\ttest-auc:0.905348\n",
      "[65]\ttrain-auc:0.999993\ttest-auc:0.911804\n",
      "[70]\ttrain-auc:0.999993\ttest-auc:0.909136\n",
      "[75]\ttrain-auc:0.999991\ttest-auc:0.91418\n",
      "[80]\ttrain-auc:0.999991\ttest-auc:0.910261\n",
      "[85]\ttrain-auc:0.999991\ttest-auc:0.90663\n",
      "[90]\ttrain-auc:0.999991\ttest-auc:0.917792\n",
      "[95]\ttrain-auc:0.999991\ttest-auc:0.919595\n",
      "[100]\ttrain-auc:0.999996\ttest-auc:0.919774\n",
      "[105]\ttrain-auc:0.999996\ttest-auc:0.923851\n",
      "[110]\ttrain-auc:0.999996\ttest-auc:0.92537\n",
      "[115]\ttrain-auc:0.999998\ttest-auc:0.9277\n",
      "[120]\ttrain-auc:0.999998\ttest-auc:0.928919\n",
      "[125]\ttrain-auc:1\ttest-auc:0.927304\n",
      "[130]\ttrain-auc:1\ttest-auc:0.92512\n",
      "[135]\ttrain-auc:1\ttest-auc:0.925865\n",
      "[140]\ttrain-auc:1\ttest-auc:0.924607\n",
      "[145]\ttrain-auc:1\ttest-auc:0.925309\n",
      "[150]\ttrain-auc:1\ttest-auc:0.923572\n",
      "[155]\ttrain-auc:1\ttest-auc:0.926062\n",
      "[160]\ttrain-auc:1\ttest-auc:0.925546\n",
      "[165]\ttrain-auc:1\ttest-auc:0.923301\n",
      "[170]\ttrain-auc:1\ttest-auc:0.924173\n",
      "[175]\ttrain-auc:1\ttest-auc:0.922455\n",
      "[180]\ttrain-auc:1\ttest-auc:0.92486\n",
      "[185]\ttrain-auc:1\ttest-auc:0.925647\n",
      "[190]\ttrain-auc:1\ttest-auc:0.924519\n",
      "[195]\ttrain-auc:1\ttest-auc:0.923194\n",
      "[200]\ttrain-auc:1\ttest-auc:0.921455\n",
      "[205]\ttrain-auc:1\ttest-auc:0.921596\n",
      "[210]\ttrain-auc:1\ttest-auc:0.921048\n",
      "[215]\ttrain-auc:1\ttest-auc:0.921191\n",
      "[220]\ttrain-auc:1\ttest-auc:0.920412\n",
      "Stopping. Best iteration:\n",
      "[122]\ttrain-auc:0.999998\ttest-auc:0.929251\n",
      "\n",
      "28561/28561 [==============================] - 1s 41us/step\n",
      "28561/28561 [==============================] - 1s 39us/step\n",
      "28561/28561 [==============================] - 1s 39us/step\n",
      "28561/28561 [==============================] - 1s 41us/step\n",
      "28561/28561 [==============================] - 1s 42us/step\n",
      "28561/28561 [==============================] - 1s 39us/step\n",
      "28561/28561 [==============================] - 1s 39us/step\n",
      "28561/28561 [==============================] - 1s 39us/step\n"
     ]
    }
   ],
   "source": [
    "newFunc.trainingPipeline(rawData=Data_day_9,epochs=1,name='Day_9')\n",
    "preData9 =  newFunc.resultGenea(rawData=test_Day_9,name='Day_9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPredict = pd.concat([preData6,preData7,preData8,preData9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPredict = finalPredict.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.001235\n",
       "1        0.010431\n",
       "2        0.004917\n",
       "3        0.001011\n",
       "4        0.001606\n",
       "5        0.000432\n",
       "6        0.000402\n",
       "7        0.000495\n",
       "8        0.000562\n",
       "9        0.000284\n",
       "10       0.000549\n",
       "11       0.001914\n",
       "12       0.000597\n",
       "13       0.001092\n",
       "14       0.000756\n",
       "15       0.002419\n",
       "16       0.000811\n",
       "17       0.000700\n",
       "18       0.030667\n",
       "19       0.022607\n",
       "20       0.000669\n",
       "21       0.002419\n",
       "22       0.001037\n",
       "23       0.004898\n",
       "24       0.000419\n",
       "25       0.030573\n",
       "26       0.004703\n",
       "27       0.000299\n",
       "28       0.006900\n",
       "29       0.000331\n",
       "           ...   \n",
       "99970    0.002315\n",
       "99971    0.001215\n",
       "99972    0.001503\n",
       "99973    0.001564\n",
       "99974    0.002390\n",
       "99975    0.002028\n",
       "99976    0.002112\n",
       "99977    0.002821\n",
       "99978    0.009518\n",
       "99979    0.003147\n",
       "99980    0.003935\n",
       "99981    0.002397\n",
       "99982    0.003374\n",
       "99983    0.002820\n",
       "99984    0.100342\n",
       "99985    0.002737\n",
       "99986    0.003329\n",
       "99987    0.001175\n",
       "99988    0.001651\n",
       "99989    0.015571\n",
       "99990    0.003951\n",
       "99991    0.001280\n",
       "99992    0.002398\n",
       "99993    0.001624\n",
       "99994    0.005307\n",
       "99995    0.009109\n",
       "99996    0.002686\n",
       "99997    0.002232\n",
       "99998    0.004555\n",
       "99999    0.000948\n",
       "Name: result, Length: 100000, dtype: float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['click_id', 'is_attributed'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "5           0\n",
       "6           0\n",
       "7           0\n",
       "8           0\n",
       "9           0\n",
       "10          0\n",
       "11          0\n",
       "12          0\n",
       "13          0\n",
       "14          0\n",
       "15          0\n",
       "16          0\n",
       "17          0\n",
       "18          0\n",
       "19          0\n",
       "20          0\n",
       "21          0\n",
       "22          0\n",
       "23          0\n",
       "24          0\n",
       "25          0\n",
       "26          0\n",
       "27          0\n",
       "28          0\n",
       "29          0\n",
       "           ..\n",
       "18790439    0\n",
       "18790440    0\n",
       "18790441    0\n",
       "18790442    0\n",
       "18790443    0\n",
       "18790444    0\n",
       "18790445    0\n",
       "18790446    0\n",
       "18790447    0\n",
       "18790448    0\n",
       "18790449    0\n",
       "18790450    0\n",
       "18790451    0\n",
       "18790452    0\n",
       "18790453    0\n",
       "18790454    0\n",
       "18790455    0\n",
       "18790456    0\n",
       "18790457    0\n",
       "18790458    0\n",
       "18790459    0\n",
       "18790460    0\n",
       "18790461    0\n",
       "18790462    0\n",
       "18790463    0\n",
       "18790464    0\n",
       "18790465    0\n",
       "18790466    0\n",
       "18790467    0\n",
       "18790468    0\n",
       "Name: is_attributed, Length: 18790469, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}